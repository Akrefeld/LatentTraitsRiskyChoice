---
title: "InititalAnalysis"
author: "Antonia"
date: "04 23 2020"
output:  
  html_document:
    code_folding: hide
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = T)
library(knitr)
library(stringr)
```


```{r load}
data = read.csv("data.csv", sep = ";")
dataFit = read.csv("mixed_bic_values.csv", sep = ";")
#str(dataFit)
#sort(apply(dataFit[,3:56],2,mean))

# retun model names with mean BIC better than Baseline
goodfitnames = names(which(apply(dataFit[,3:56],2,mean) <mean(dataFit[,"Baseline"])))

meanBIC = apply(dataFit[,3:56], 2, mean)
#create vectors for Experiemnt and ID
Experiment = data$EXPERIMENT
Id = data$ï..SUBJ.ID
#remove these varibales from the datafile ued for the analysis
data= data[,-c(which(colnames(data) == "EXPERIMENT"),
which(colnames(data) == "ï..SUBJ.ID") )]

```



```{r}
#colnames(data)

data = data[ , order(names(data))]
#colnames(data)

modelNames = word(colnames(data),1, sep = "\\_")
paramNames = sub('.*\\_', '', colnames(data))

numParamModel = summary(as.factor(modelNames))

#paramNames


#data = data[, modelNames %in% goodfitnames]
#data = data[, paramNames %in% c("gamma", "epsilon")]
modelNames = word(colnames(data),1, sep = "\\_")
paramNames = sub('.*\\_', '', colnames(data))

numParamModel = summary(as.factor(modelNames))

```

## 1. Correlation between parameters within the models

The following tables summarize the parameter correlations within each model.



```{r, correlationWitthinModels}


CorrModelParams = as.data.frame(NA, nrow = c(length(unique(modelNames))), ncol= 5)
accNumbParams = 0 # strting index for columbs in data
for (m in 1:length(unique(modelNames))){
datatemp = data[,(accNumbParams+1) : (accNumbParams + as.numeric(numParamModel[unique(modelNames)[m]]))]
#print(colnames(datatemp))

CorrModelParams[m,1] = unique(modelNames)[m]
CorrModelParams[m,2] = numParamModel[unique(modelNames)[m]]
if (numParamModel[unique(modelNames)[m]] > 1) {
  
print(kable(round(cor(datatemp),2)))
  
cors = abs(cor(datatemp))
cors[cors == 1] = NA

CorrModelParams[m,3] = max(abs(cors), na.rm = T)
CorrModelParams[m,4] = mean(abs(cors), na.rm = T)
}

CorrModelParams[m,5] = paste(paramNames[modelNames == unique(modelNames)[m]], collapse = ", ")
accNumbParams = cumsum(numParamModel)[m]
}

colnames(CorrModelParams) = c("Name", "nPars", "maxCor", "meanCor", "Pars")

for ( m in 1:length(CorrModelParams[,1])){
  
  CorrModelParams$meanFit[m] = meanBIC[which(names(meanBIC) == CorrModelParams$Name[m])]
  
  
}


#the larger the numbe rof params, the smaller the correlations
#cor.test(CorrModelParams$nPars, CorrModelParams$meanCor)
```

The folllowing tables sorts the models by the mean correaltion between the parameters, reporting first the 10 models with the highest correlations and subsequently the 10 models with the lowest correlations
```{r}

CorrModelParams[order(CorrModelParams$meanCor, decreasing = T),][1:10,]

CorrModelParams[order(CorrModelParams$meanCor, decreasing = F),][1:10,]
```

There seeems to be some relation between the model fit, (the average indiviudal BIC) and the correlation between parameters. This indicates that higher correlation is associated with better fit. this might be a function of the parameters in the model that increase fit, but also tend to merely identifiable


```{r}

plot(CorrModelParams$meanFit[ CorrModelParams$meanFit<mean(dataFit[,"Baseline"])], CorrModelParams$meanCor[ CorrModelParams$meanFit<mean(dataFit[,"Baseline"])], xlab = "meanBIC", ylab ="meanCor")
plot(CorrModelParams$nPars, CorrModelParams$meanCor)

```

## 2. Correlation of similar mdoel parameter across models

I calculated the correlation between for instance the response noise parameters across different models to estimate, which model's reponse noise parameter explains most variacne in the pther models' response noise parameters. For now, I did this only for resposne noise (epsilon), curvature (gamma) and probability weighting (Tau). This analysis can be extended to other structures and parameters that are similar across models. The output return the list of parameters and their average correlation with the other corresponding parameters in decreasing order. In other words, the model's parameter on top of the list can be assumed to be the most general implementation of the parameter. 

```{r}

library(stringr)
Sigmas = str_detect(colnames(data), "sigma")
Epsilons = str_detect(colnames(data), "epsilon")
CPT = str_detect(colnames(data), "CPT")
Gammas = str_detect(colnames(data), "gamma")

Taus = str_detect(colnames(data), "tau")

## Mean correlation of model specific epsilon, wiht other epsilons ___ must consider rank order correlation
EpsilonsCorr = apply(abs(cor(data[,which(Epsilons == T)], method = "spearman")),2,mean)
#kable(round(cor(data[,which(Epsilons == T)]),2))
mean(cor(data[,which(Epsilons == T)], method = "spearman"))
sort(EpsilonsCorr, decreasing = T)

GammasCorr = apply(abs(cor(data[,which(Gammas == T)], method = "spearman")),2,mean)
# kable(round(cor(data[,which(Gammas == T)]),2))
mean(cor(data[,which(Gammas == T)], method = "spearman"))
sort(GammasCorr, decreasing = T)

TausCorr = apply(abs(cor(data[,which(Taus == T)], method = "spearman")),2,mean)
# kable(round(cor(data[,which(Gammas == T)]),2))
mean(cor(data[,which(Taus == T)], method = "spearman"))
sort(TausCorr, decreasing = T)


GammasCorrMAtrix = cor(data[,which(Epsilons == T)], method = "spearman")


```

## 3. Correlation of all parameters across models

The following graph plots the network of all parameters, across all models. The color as well as the first number on the nodes indicates parameter type. Correlations above .3 are illustrated with lines, and position. Positive correlations are illustrated with green lines and negative correlations are illustrated with red lines. Clsuters of tau, epsilon and gamma emerge



```{r}
library(psych)
library(qgraph)


models = unique(modelNames)


Listmodels = list(which(modelNames ==models[1]))

for (i in 1: length(models)){
Listmodels =  append(Listmodels, list(which(modelNames ==models[i])))}

params = unique(paramNames)
Listparams = list(which(paramNames ==params[1]))

for (i in 1:length(params)){
Listparams =  append(Listparams, list(which(paramNames ==params[i])))}


modelFAC = as.numeric(as.factor(modelNames))
paramFAC = as.factor(paramNames)


realNames = colnames(data)
colnames(data)  = seq(1:length(colnames(data)))
for (c in 1:dim(data)[2]){
colnames(data)[c] = paste0(paramFAC[c], "_" , modelFAC[c])
}
qgraph(cor(data), minimum = .3, layout = "spring", vsize = 4, groups = Listparams, legend = T, graph = "cor")

```

1 alpha   
2 beta
3 chi
4 delta
5 epsilon
6 gamma
7 iota
8 kappa
9 lambda
10 mu
11 nu
12 omega
13 phi
14 psi
15 rho
16 sigma
17 tau
18 theta
19 upsilon


TO DO: Group parameters more precisely after roel in the model porb. weighting, subjective values, noise....
Known: Epsilon = response noise, Gamma = Curvature, Tau = ~ probability weighting 
Those clusters 





Here, color as well as the second number on the node indicates the model 

```{r}

qgraph(cor(data), minimum = .3, layout = "spring", vsize = 4, groups = Listmodels)

as.data.frame(cbind(seq(1:length(models)), models ))
  
```

Now the same thing, but only  for gamma, epsilon  and tau.



```{r}

dataRaw = read.csv("data.csv", sep = ";")

Experiment = dataRaw$EXPERIMENT
Id = dataRaw$ï..SUBJ.ID
#remove these varibales from the datafile ued for the analysis
dataRaw= dataRaw[,-c(which(colnames(dataRaw) == "EXPERIMENT"),
which(colnames(dataRaw) == "ï..SUBJ.ID") )]

paramNames = sub('.*\\_', '', colnames(dataRaw))

dataEG = dataRaw[, paramNames %in% c("gamma", "epsilon", "tau")]
modelNamesEG = word(colnames(dataEG),1, sep = "\\_")
paramNamesEG = sub('.*\\_', '', colnames(dataEG))

numParamModelEG = summary(as.factor(modelNamesEG))


modelsEG = unique(modelNamesEG)


ListmodelsEG = list(which(modelNamesEG ==modelsEG[1]))

for (i in 1: length(modelsEG)){
ListmodelsEG =  append(ListmodelsEG, list(which(modelNamesEG ==modelsEG[i])))}

paramsEG = unique(paramNamesEG)
ListparamsEG = list(which(paramNamesEG ==paramsEG[1]))

for (i in 1:length(paramsEG)){
ListparamsEG =  append(ListparamsEG, list(which(paramNamesEG ==paramsEG[i])))}


modelFACEG = as.factor(modelNamesEG)
paramFACEG = as.factor(paramNamesEG)


realNamesEG = colnames(dataEG)
colnames(dataEG)  = seq(1:length(colnames(dataEG)))
for (c in 1:dim(dataEG)[2]){
#colnames(dataEG)[c] = paste0(paramFACEG[c], "_" , modelFACEG[c])
colnames(dataEG)[c] = paste0(modelFACEG[c])
}

qgraph(cor(dataEG), minimum = .3, layout = "spring", vsize = 7, groups = ListparamsEG)





```

green = epsilon, light blue = gamma, purple = tau

To DO: find a good analysis to prove these clsuters, factors. Include fit of the models in this visulaization and analysis, as well as the variation of parameter values between samples,



      
      
```{r, eval = F}        

-c(which(colnames(data) == "EXPERIMENT"),
which(colnames(data) == "ï..SUBJ.ID") ) 

# 
# ## Mean absolute Param Correlations in Models with Epsilon
CorrModelParams[CorrModelParams$Name %in% modelNames[which(Epsilons == T)],4]

CorrModelParams[CorrModelParams$Name %in% modelNames[which(Gammas == T)],4]
CorrModelParams[!(CorrModelParams$Name %in% modelNames[which(Epsilons == T)]),4]
# 
# ## Mean absolute Param Correlations in Models with Gamma
# CorrModelParams[CorrModelParams$Name %in% modelNames[which(Gammas == T)],4]
# CorrModelParams[!(CorrModelParams$Name %in% modelNames[which(Gammas == T)]),4]


```

### Check for differences between Experiments

```{r, eval = F}
###  Diffferences between Experiments

anova(lm(CPT.TK__epsilon~EXPERIMENT, data = data))
round(with(data, tapply(CPT.TK__epsilon, EXPERIMENT, mean)),3)
## where do these extreme values come from?
round(with(data, tapply(CPT.TK__epsilon, EXPERIMENT, median)),3)

anova(lm(CPT.TK__gamma~EXPERIMENT, data = data))
with(data, tapply(CPT.TK__gamma, EXPERIMENT, mean))
with(data, tapply(CPT.TK__gamma, EXPERIMENT, median))
```

needs to be elaborated further